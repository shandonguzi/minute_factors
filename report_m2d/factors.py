import pandas as pd
import numpy as np
from scipy.stats import skew
from sklearn.linear_model import LinearRegression
import pandas as pd
import numpy as np
from numba import jit
from numpy.lib.stride_tricks import as_strided as stride


'''
å› å­è®¡ç®—å‡åŸºäºpandas dataframe
'''


# '''
# rollingå¤šåˆ—
# '''
# def roll(df, w, min, **kwargs):
#     v = df.values
#     d0, d1 = v.shape
#     s0, s1 = v.strides

#     a = stride(v, (d0 - (w - 1), w, d1), (s0, s0, s1))
#     valid_windows = [values for values in a if len(values) >= min]

#     rolled_df = pd.concat({
#         row: pd.DataFrame(values, columns=df.columns)
#         for row, values in zip(df.index[w-1:], valid_windows)
#     })

#     return rolled_df.groupby(level=0, **kwargs)


# '''
# QRSæŒ‡æ ‡
# '''
# def QRS(df):
#     model = LinearRegression()
#     model.fit(X=df['low'].values.reshape(-1, 1), y=df['high'].values)
#     ğ›½ = model.coef_[0]
#     R2 = model.score(X=df['low'].values.reshape(-1, 1), y=df['high'].values)
#     return ğ›½ * R2


@jit(nopython=True)
def QRS(df):
    x = df[:, 0]
    if x.shape[0] < 50:
        return np.nan
    y = df[:, 1]

    x_mean = x.mean()
    y_mean = y.mean()

    try:
        beta = (y * (x - x_mean)).sum() / ((x - x_mean)**2).sum()
        alpha = y_mean - beta * x_mean
        y_pred = alpha + beta * x
        SS_tot = ((y - y_mean)**2).sum()
        SS_res = ((y - y_pred)**2).sum()
        R_squared = 1 - (SS_res / SS_tot)
        
        return beta * R_squared
    
    except:
        return np.nan


def corr(df):
    if df[:, 0].shape[0] < 50:
        return np.nan
    return np.corrcoef(df[:, 0], df[:, 1])[0, 1]


def QRS_beta(df):
    x = df[:, 0]
    if x.shape[0] < 50:
        return np.nan
    y = df[:, 1]

    x_mean = x.mean()

    try:
        beta = (y * (x - x_mean)).sum() / ((x - x_mean)**2).sum()
        return beta
    except:
        return np.nan  


class B_feature:

    def __init__(self):
        trading_hours = [
            ("09:30", "10:00"), ("10:00", "10:30"), 
            ("10:30", "11:00"), ("11:00", "11:30"), 
            ("13:00", "13:30"), ("13:30", "14:00"), 
            ("14:00", "14:30"), ("14:30", "15:00")
            ]
        self.half_hour_dict = {n: {"start": pd.to_datetime(start).time(), "end": pd.to_datetime(end).time()} for n, (start, end) in enumerate(trading_hours, 1)}

    '''
    report: åæ³°è¯åˆ¸â€”â€”åŸºäºå…¨é¢‘æ®µé‡ä»·ç‰¹å¾çš„é€‰è‚¡æ¨¡å‹
    '''

    def late_skew_ret(self, data, tail_period=30):
        # å°¾ç›˜æ”¶ç›Šç‡ååº¦(é»˜è®¤å°¾ç›˜æ˜¯æœ€å30åˆ†é’Ÿ)
        late_skew_ret = skew(data.iloc[-tail_period:]['ret'], nan_policy='omit')
        return late_skew_ret

    def down_vol_perc(self, data):
        # ä¸‹è¡Œæ”¶ç›Šç‡æ³¢åŠ¨å æ¯”(é»˜è®¤ä¸‹è¡Œæ”¶ç›Šç‡ä¸ºå°äºå‡å€¼çš„æ”¶ç›Šç‡ï¼Œä¹Ÿå¯æ”¹ä¸ºå°äº0çš„æ”¶ç›Šç‡)
        mean_ret = data['ret'].mean()
        downside_volatility = data[data['ret'] < mean_ret]['ret'].std()
        total_volatility = data['ret'].std()
        down_vol_perc = downside_volatility / total_volatility
        return down_vol_perc


    def corr_ret_lastret(self, data):
        # å‰åä¸¤åˆ†é’Ÿæ”¶ç›Šç‡çš„ç›¸å…³æ€§
        corr_ret_lastret = data['ret'].corr(data['ret'].shift(1))
        return corr_ret_lastret


    def corr_close_nextopen(self, data):
        # å‰ä¸€åˆ†é’Ÿæ”¶ç›˜ä»·ä¸åä¸€åˆ†é’Ÿå¼€ç›˜ä»·çš„ç›¸å…³æ€§
        corr_close_nextopen = data['close'].shift(1).corr(data['open'].shift(-1))
        return corr_close_nextopen


    def volume_perc_n(self, data, n_half_hour):
        # ç¬¬nä¸ªåŠå°æ—¶æˆäº¤é‡å å…¨å¤©æˆäº¤é‡æ¯”ä¾‹
        start_time = self.half_hour_dict[n_half_hour]["start"]
        end_time = self.half_hour_dict[n_half_hour]["end"]
        volume_perc_n = data[(data['dt'].dt.time >= start_time) & (data['dt'].dt.time < end_time)]['volume'].sum() / data['volume'].sum()
        return volume_perc_n


    def early_corr_volume_ret(self, data):
        # æ—©ç›˜æˆäº¤é‡ä¸æ”¶ç›Šç‡çš„ç›¸å…³æ€§(æ—©ç›˜é»˜è®¤ä¸ºå¼€ç›˜åˆ°10ç‚¹)
        early_data = data[data['dt'].dt.time <= pd.to_datetime('10:00').time()]
        early_corr_volume_ret = early_data['volume'].corr(early_data['ret'])
        return early_corr_volume_ret


    def corr_volume_amplitude(self, data):
        # æˆäº¤é‡ä¸æŒ¯å¹…çš„ç›¸å…³æ€§
        corr_volume_amplitude = ((data['high'] - data['low']) / data['open'] * 100).corr(data['volume'])
        return corr_volume_amplitude
    
    '''
    report: ä¸­é‡‘â€”â€”é‡åŒ–å¤šå› å­ç³»åˆ—(12)
    '''

    def mmt_pm(self, data):
        # ä¸‹åˆç›˜åŠ¨é‡
        return (data['close'].iloc[-1] - data['close'].iloc[-120]) / data['close'].iloc[-120]
    

    def mmt_am(self, data):
        # ä¸Šåˆç›˜åŠ¨é‡
        return (data['close'].iloc[120] - data['close'].iloc[0]) / data['close'].iloc[0]
    

    def mmt_last30(self, data):
        # å°¾ç›˜30åˆ†é’ŸåŠ¨é‡
        return (data['close'].iloc[-1] - data['close'].iloc[-30]) / data['close'].iloc[-30]
    

    def mmt_paratio(self, data):
        # ä¸Šä¸‹åˆç›˜åŠ¨é‡å·®
        return self.mmt_pm(data) - self.mmt_am(data)
    

    def mmt_between(self, data):
        # å»å¤´å°¾åŠ¨é‡
        return (data['close'].iloc[-30] - data['close'].iloc[30]) / data['close'].iloc[30]
    

    def mmt_ols_qrs(self, data, window_size=50):

        '''
        åˆ†é’ŸQRSæŒ‡æ ‡(è¿‡å»50æ ¹kçº¿ï¼Œè¿™æ ·ä¼šå¾—åˆ°190ä¸ªå€¼ï¼Œä½†åº”è¯¥åªæœ‰ä¸€ä¸ªå€¼ï¼Œå­˜ç–‘ï¼Œæ­¤å¤„æ±‚QRSçš„å‡å€¼)
        QRSæŒ‡æ ‡å‚è€ƒâ€”â€”20210121-é‡åŒ–æ‹©æ—¶ç³»åˆ—ï¼ˆ1ï¼‰ï¼šé‡‘èå·¥ç¨‹è§†è§’ä¸‹çš„æŠ€æœ¯æ‹©æ—¶è‰ºæœ¯-åˆ˜å‡ä¼Ÿ

        '''
        # è‡ªå®šä¹‰rollï¼Œé€Ÿåº¦å¤ªæ…¢
        # return data.pipe(roll, w=window_size, min=window_size).apply(lambda x: QRS(x)).mean()

        # numbaé€Ÿåº¦å¿«ï¼Œtryé˜²æ­¢æ¶¨åœè·Œåœè‚¡ç¥¨å¯¼è‡´çš„æŠ¥é”™
        return data[['low', 'high']].rolling(window_size, method='table').apply(QRS, raw=True, engine='numba').iloc[:, 0].mean()
    

    def mmt_ols_corr_square_mean(self, data, window_size=50):
        # åˆ†é’ŸQRSè¡ç”Ÿå›å½’R2
        # return data.pipe(roll, w=window_size, min=window_size).apply(lambda x: x['high'].corr(x['low'])).pow(2).mean()
        return data[['low', 'high']].rolling(window_size, method='table').apply(corr, raw=True, engine='numba').iloc[:, 0].pow(2).mean()
    

    def mmt_ols_corr_mean(self, data, window_size=50):
        # åˆ†é’ŸQRSè¡ç”Ÿç›¸å…³ç³»æ•°å‡å€¼
        # return data.pipe(roll, w=window_size, min=window_size).apply(lambda x: x['high'].corr(x['low'])).mean()
        return data[['low', 'high']].rolling(window_size, method='table').apply(corr, raw=True, engine='numba').iloc[:, 0].mean()
    

    def mmt_ols_beta_mean(self, data, window_size=50):
        # åˆ†é’ŸQRSè¡ç”Ÿbetaå‡å€¼
        # return data.pipe(roll, w=window_size, min=window_size).apply(lambda x: LinearRegression().fit(X=x['low'].values.reshape(-1, 1), y=x['high'].values).coef_[0]).mean()
        return data[['low', 'high']].rolling(window_size, method='table').apply(QRS_beta, raw=True, engine='numba').iloc[:, 0].mean()
    

    def mmt_ols_beta_zscore_last(self, data, window_size=50):
        # åˆ†é’ŸQRSè¡ç”Ÿbetaæ ‡å‡†åˆ†
        # ğ›½_list = data.pipe(roll, w=window_size, min=window_size).apply(lambda x: LinearRegression().fit(X=x['low'].values.reshape(-1, 1), y=x['high'].values).coef_[0])
        # return (ğ›½_list[-1] - ğ›½_list.mean()) / ğ›½_list.std()
        qrs_beta = data[['low', 'high']].rolling(window_size, method='table').apply(QRS_beta, raw=True, engine='numba').iloc[:, 0]
        return (qrs_beta.iloc[-1] - qrs_beta.mean()) / qrs_beta.std()
    

    def mmt_topnVolumeRet(self, data, window_size):
        # né¡¶é‡æˆäº¤åŠ¨é‡
        top_n = data[data['volume'] >= data['volume'].nlargest(window_size).min()]
        return (top_n['close'].iloc[-1] - top_n['close'].iloc[0]) / top_n['close'].iloc[0]
    

    def mmt_bottomnVolumeRet(self, data, window_size):
        # nåº•é‡æˆäº¤åŠ¨é‡
        bottom_n = data[data['volume'] <= data['volume'].nsmallest(window_size).max()]
        return (bottom_n['close'].iloc[-1] - bottom_n['close'].iloc[0]) / bottom_n['close'].iloc[0]


    def vol_volumelmin(self ,data):
        # åˆ†é’Ÿæˆäº¤é‡æ ‡å‡†å·®
        return data['volume'].std()
    

    def vol_rangelmin(self ,data):
        # åˆ†é’Ÿææ¯”æ ‡å‡†å·®
        return (data['high'] / data['low']).std()
    

    def vol_returnlmin(self ,data):
        # åˆ†é’Ÿæ”¶ç›Šç‡æ ‡å‡†å·®
        return data['ret'].std()
    

    def vol_upVol(self, data):
        # ä¸Šè¡Œæ³¢åŠ¨ç‡
        mean_ret = data['ret'].mean()
        up_volatility = data[data['ret'] > mean_ret]['ret'].std()
        return up_volatility
    

    def vol_upRatio(self, data):
        # ä¸Šè¡Œæ”¶ç›Šç‡æ³¢åŠ¨å æ¯”
        mean_ret = data['ret'].mean()
        up_volatility = data[data['ret'] > mean_ret]['ret'].std()
        total_volatility = data['ret'].std()
        vol_upRatio = up_volatility / total_volatility
        return vol_upRatio
    

    def vol_downVol(self, data):
        # ä¸‹è¡Œæ³¢åŠ¨ç‡
        mean_ret = data['ret'].mean()
        down_volatility = data[data['ret'] < mean_ret]['ret'].std()
        return down_volatility
    

    # def vol_downRatio(self, data):
    #     # ä¸‹è¡Œæ”¶ç›Šç‡æ³¢åŠ¨å æ¯”ï¼ŒåŒåæ³°down_vol_perc
    #     mean_ret = data['ret'].mean()
    #     down_volatility = data[data['ret'] < mean_ret]['ret'].std()
    #     total_volatility = data['ret'].std()
    #     vol_downRatio = down_volatility / total_volatility
    #     return vol_downRatio